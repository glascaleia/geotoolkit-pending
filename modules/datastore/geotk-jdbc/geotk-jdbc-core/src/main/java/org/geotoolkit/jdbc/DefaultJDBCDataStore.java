/*
 *    Geotoolkit - An Open Source Java GIS Toolkit
 *    http://www.geotoolkit.org
 *
 *    (C) 2002-2008, Open Source Geospatial Foundation (OSGeo)
 *    (C) 2009-2010, Geomatys
 *
 *    This library is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU Lesser General Public
 *    License as published by the Free Software Foundation;
 *    version 2.1 of the License.
 *
 *    This library is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *    Lesser General Public License for more details.
 */
package org.geotoolkit.jdbc;


import java.io.IOException;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.logging.Level;

import org.geotoolkit.feature.SchemaException;
import org.geotoolkit.jdbc.fid.PrimaryKey;
import org.geotoolkit.jdbc.fid.PrimaryKeyColumn;
import org.geotoolkit.jdbc.fid.PrimaryKeyFIDValidator;
import org.geotoolkit.jdbc.fid.NullPrimaryKey;
import org.geotoolkit.jdbc.dialect.PreparedStatementSQLDialect;
import org.geotoolkit.jdbc.dialect.SQLDialect;
import org.geotoolkit.jdbc.reverse.DataBaseModel;
import org.geotoolkit.storage.DataStoreException;
import org.geotoolkit.data.DataStoreRuntimeException;
import org.geotoolkit.data.DataUtilities;
import org.geotoolkit.data.FeatureReader;
import org.geotoolkit.data.FeatureWriter;
import org.geotoolkit.data.jdbc.FilterToSQL;
import org.geotoolkit.data.memory.GenericFilterFeatureIterator;
import org.geotoolkit.data.memory.GenericReprojectFeatureIterator;
import org.geotoolkit.data.memory.GenericRetypeFeatureIterator;
import org.geotoolkit.data.query.DefaultQueryCapabilities;
import org.geotoolkit.data.query.Join;
import org.geotoolkit.data.query.Query;
import org.geotoolkit.data.query.QueryBuilder;
import org.geotoolkit.data.query.QueryCapabilities;
import org.geotoolkit.data.query.Selector;
import org.geotoolkit.data.query.Source;
import org.geotoolkit.data.query.TextStatement;
import org.geotoolkit.factory.Hints;
import org.geotoolkit.feature.AttributeDescriptorBuilder;
import org.geotoolkit.feature.DefaultName;
import org.geotoolkit.feature.simple.SimpleFeatureBuilder;
import org.geotoolkit.feature.FeatureTypeBuilder;
import org.geotoolkit.filter.capability.DefaultFilterCapabilities;
import org.geotoolkit.filter.visitor.CapabilitiesFilterSplitter;
import org.geotoolkit.filter.visitor.FilterAttributeExtractor;
import org.geotoolkit.filter.visitor.SimplifyingFilterVisitor;
import org.geotoolkit.geometry.jts.JTSEnvelope2D;
import org.geotoolkit.jdbc.dialect.SQLQueryBuilder;
import org.geotoolkit.jdbc.fid.AutoGeneratedPrimaryKeyColumn;
import org.geotoolkit.jdbc.fid.SequencedPrimaryKeyColumn;
import org.geotoolkit.referencing.CRS;

import org.opengis.feature.Feature;
import org.opengis.feature.simple.SimpleFeature;
import org.opengis.feature.simple.SimpleFeatureType;
import org.opengis.feature.type.AttributeDescriptor;
import org.opengis.feature.type.FeatureType;
import org.opengis.feature.type.GeometryDescriptor;
import org.opengis.feature.type.Name;
import org.opengis.feature.type.PropertyDescriptor;
import org.opengis.filter.Filter;
import org.opengis.filter.expression.PropertyName;
import org.opengis.filter.identity.FeatureId;
import org.opengis.geometry.Envelope;
import org.opengis.util.FactoryException;
import org.opengis.referencing.crs.CoordinateReferenceSystem;

/**
 * @author Johann Sorel (Geomatys)
 *
 * @module pending
 */
public final class DefaultJDBCDataStore extends AbstractJDBCDataStore {

    private static enum EditMode{
        UPDATE,
        INSERT,
        UPDATE_AND_INSERT
    }

    private final DataBaseModel dbmodel = new DataBaseModel(this);
    private final QueryCapabilities capabilities = new DefaultQueryCapabilities(true, new String[]{Query.GEOTK_QOM, CUSTOM_SQL});
    final SQLQueryBuilder queryBuilder = new SQLQueryBuilder(this);

    DefaultJDBCDataStore(final String namespace){
        super(namespace);
    }

    @Override
    public DataBaseModel getMetaModel(){
        return dbmodel;
    }

    @Override
    public boolean isWritable(final Name typeName) throws DataStoreException {
        final PrimaryKey key = dbmodel.getPrimaryKey(typeName);
        return key != null && !(key instanceof NullPrimaryKey);
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public synchronized Set<Name> getNames() throws DataStoreException {
        return dbmodel.getNames();
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public FeatureType getFeatureType(final Name typeName) throws DataStoreException {
        typeCheck(typeName);
        return dbmodel.getFeatureType(typeName);
    }

    /**
     * Handle standard QOM queries and SQL queries.
     */
    @Override
    public FeatureType getFeatureType(final Query query) throws DataStoreException, SchemaException {

        if(CUSTOM_SQL.equalsIgnoreCase(query.getLanguage())){
            
            final TextStatement txt = (TextStatement) query.getSource();
            final String sql = txt.getStatement();

            Connection cx = null;
            Statement stmt = null;
            ResultSet rs = null;
            try {
                cx = getDataSource().getConnection();
                stmt = cx.createStatement();
                rs = stmt.executeQuery(sql);
                return getMetaModel().analyzeResult(rs, query.getTypeName());
            } catch (SQLException ex) {
                throw new DataStoreException(ex);
            }finally{
                closeSafe(cx,stmt,rs);
            }
        }

        return super.getFeatureType(query);
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public QueryCapabilities getQueryCapabilities() {
        return capabilities;
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public FeatureReader getFeatureReader(final Query query) throws DataStoreException {

        final Source source = query.getSource();

        final FeatureReader reader;
        if(source instanceof Join){
            reader = getCrossFeatureReader(query);
        }else if(source instanceof Selector){
            reader = getSimpleFeatureReader(query);
        }else if(source instanceof TextStatement){
            reader = getSQLFeatureReader(query);
        }else{
            throw new DataStoreException("Unexpected source type : " + source);
        }

        //take care of potential hints, like removing primary keys
        final QueryBuilder qb = new QueryBuilder();
        qb.setTypeName(new DefaultName("remaining"));
        qb.setHints(query.getHints());
        return handleRemaining(reader, qb.buildQuery());
    }

    /**
     * Generate a reader from a join query.
     *
     * @param query
     * @return FeatureReader
     * @throws DataStoreException
     */
    private FeatureReader getCrossFeatureReader(final Query query) throws DataStoreException {
        /*
         * Query should look like :
          SELECT * FROM
          (SELECT * FROM (SELECT "id","version","userId","timestamp","changeset",encode(asBinary(force_2d("geometry"),'XDR'),'base64') as "geometry" FROM "Way") as l
          INNER JOIN
          (SELECT "wayId","k","v" FROM "WayTag") as r ON l."id" = r."wayId") as l
          LEFT JOIN
          (SELECT "wayId","nodeId","index" FROM "WayMember") as r ON l."id" = r."wayId"
         */

        final LinkedHashMap<String, List<AttributeDescriptor>> atts = new LinkedHashMap<String, List<AttributeDescriptor>>();
        final List<PrimaryKey> pkeys = new ArrayList<PrimaryKey>();

        //build the sql query
        final StringBuilder querySQL = new StringBuilder();
        prepareSelect(query.getSource(), querySQL, atts, pkeys, query.getHints());
        final String sql = querySQL.toString();

        //build the new feature type
        final FeatureTypeBuilder sftb = new FeatureTypeBuilder();
        final AttributeDescriptorBuilder adb = new AttributeDescriptorBuilder();
        sftb.setName(getNamespaceURI(),"crossQuery");

        for(Entry<String,List<AttributeDescriptor>> entry : atts.entrySet()){
            final String selectorName = entry.getKey();
            for(AttributeDescriptor desc : entry.getValue()){
                adb.reset();
                adb.copy(desc);
                final Name oldName = adb.getName();
                adb.setName(new DefaultName(oldName.getNamespaceURI()+"-"+selectorName, oldName.getLocalPart()));
                sftb.add(adb.buildDescriptor());
            }
        }
        final SimpleFeatureType querySchema = sftb.buildSimpleFeatureType();

        final List<PrimaryKeyColumn> columns = new ArrayList<PrimaryKeyColumn>();
        for(PrimaryKey pkey : pkeys){
            columns.addAll(pkey.getColumns());
        }
        final PrimaryKey pkCombine = new PrimaryKey("crossKey", columns);

        //grab connection
        final Connection cx;
        try {
            cx = getDataSource().getConnection();
        } catch (SQLException ex) {
            throw new DataStoreException(ex);
        }

        //create the reader
        FeatureReader<SimpleFeatureType, SimpleFeature> reader;

        try {
            // this allows PostGIS to page the results and respect the fetch size
            // if (getState().getTransaction() == Transaction.AUTO_COMMIT)
            cx.setAutoCommit(false);

            getLogger().fine(sql);

            reader = new JDBCFeatureReader( sql, cx, this, querySchema.getName(), querySchema, pkCombine, query.getHints() );
        } catch (SQLException e) {
            // close the connection
            closeSafe(cx);
            // safely rethrow
            throw new DataStoreException(e);
        } catch (IOException e) {
            // close the connection
            closeSafe(cx);
            // safely rethrow
            throw new DataStoreException(e);
        }

        final Filter filter = query.getFilter();
        if(filter != Filter.INCLUDE){
            reader = GenericFilterFeatureIterator.wrap(reader, filter);
        }

        return reader;
    }

    private void prepareSelect(final Source source, final StringBuilder sql, final LinkedHashMap<String, List<AttributeDescriptor>> att,
            final List<PrimaryKey> pkeys, final Hints hints) throws DataStoreException{
        if(source instanceof Join){
            prepareSelect((Join)source, sql, att, pkeys, hints);
        }else if(source instanceof Selector){
            prepareSelect((Selector)source, sql, att, pkeys, hints);
        }else{
            throw new IllegalArgumentException("Unknowned source type : "+ source);
        }
    }

    private void prepareSelect(final Join source, final StringBuilder sql, final LinkedHashMap<String, List<AttributeDescriptor>> att,
            final List<PrimaryKey> pkeys, final Hints hints) throws DataStoreException{

        final Source leftSource = source.getLeft();
        final Source rightSource = source.getRight();
        final PropertyName leftProp = (PropertyName) source.getJoinCondition().getExpression1();
        final PropertyName rightProp = (PropertyName) source.getJoinCondition().getExpression2();

        sql.append("SELECT * FROM (");
        prepareSelect(leftSource, sql, att, pkeys, hints);
        sql.append(") as l ");
        switch(source.getJoinType()){
            case INNER :        sql.append("INNER");break;
            case LEFT_OUTER :   sql.append("LEFT");break;
            case RIGHT_OUTER :  sql.append("RIGHT");break;
        }
        sql.append(" JOIN (");
        prepareSelect(rightSource, sql, att, pkeys, hints);
        sql.append(") as r ON l.");
        dialect.encodeColumnName(DefaultName.valueOf(leftProp.getPropertyName()).getLocalPart(), sql);
        sql.append(" = r.");
        dialect.encodeColumnName(DefaultName.valueOf(rightProp.getPropertyName()).getLocalPart(), sql);
    }

    private void prepareSelect(final Selector source, final StringBuilder sql, final LinkedHashMap<String, List<AttributeDescriptor>> att,
            final List<PrimaryKey> pkeys, final Hints hints) throws DataStoreException{
        final SimpleFeatureType type = (SimpleFeatureType) getFeatureType(source.getFeatureTypeName());
        final PrimaryKey pk = dbmodel.getPrimaryKey(type.getName());

        sql.append("SELECT ");

        final List<AttributeDescriptor> descs = type.getAttributeDescriptors();
        for(AttributeDescriptor desc : descs){
            if (desc instanceof GeometryDescriptor) {
                queryBuilder.encodeGeometryColumn((GeometryDescriptor) desc, sql, hints);
                dialect.encodeColumnAlias(desc.getLocalName(), sql);
            }else{
                dialect.encodeColumnName(desc.getLocalName(), sql);
            }
            sql.append(',');
        }

        sql.setLength(sql.length()-1);
        sql.append(" FROM ");
        dialect.encodeTableName(type.getTypeName(), sql);

        att.put(source.getSelectorName(), descs);
        pkeys.add(pk);
    }

    private FeatureReader getSimpleFeatureReader(final Query query) throws DataStoreException {
        final SimpleFeatureType type = (SimpleFeatureType) getFeatureType(query.getTypeName());
        final PrimaryKey pkey = dbmodel.getPrimaryKey(query.getTypeName());

        // split the filter
        final Filter[] split = splitFilter(query.getFilter(),type);
        final Filter preFilter = split[0];
        final Filter postFilter = split[1];

        // rebuild a new query with the same params, but just the pre-filter
        final QueryBuilder builder = new QueryBuilder(query);
        builder.setFilter(preFilter);
        if(query.getResolution() != null){
            builder.getHints().add(new Hints(RESAMPLING, query.getResolution()));
        }
        final Query preQuery = builder.buildQuery();

        // Build the feature type returned by this query. Also build an eventual extra feature type
        // containing the attributes we might need in order to evaluate the post filter
        SimpleFeatureType querySchema;
        SimpleFeatureType returnedSchema;
        if(query.retrieveAllProperties()) {
            returnedSchema = querySchema = type;
        } else {
            returnedSchema = (SimpleFeatureType)FeatureTypeBuilder.retype(type, query.getPropertyNames());
            final FilterAttributeExtractor extractor = new FilterAttributeExtractor(type);
            postFilter.accept(extractor, null);
            final Name[] extraAttributes = extractor.getAttributeNames();
            final List<Name> allAttributes = new ArrayList<Name>(Arrays.asList(query.getPropertyNames()));
            for (Name extraAttribute : extraAttributes) {
                if(!allAttributes.contains(extraAttribute)) {
                    allAttributes.add(extraAttribute);
                }
            }

            //ensure we have the primarykeys
            pkLoop :
            for(PrimaryKeyColumn pkc : pkey.getColumns()){
                final String pkcName = pkc.getName();
                for(Name n : allAttributes){
                    if(n.getLocalPart().equals(pkcName)){
                        continue pkLoop;
                     }
                 }
                //add the pk attribut
                allAttributes.add(type.getDescriptor(pkcName).getName());
             }

            final Name[] allAttributeArray = allAttributes.toArray(new Name[allAttributes.size()]);
            querySchema = (SimpleFeatureType)FeatureTypeBuilder.retype(type, allAttributeArray);
        }

        //grab connection
        final Connection cx;
        try {
            cx = getDataSource().getConnection();
        } catch (SQLException ex) {
            throw new DataStoreException(ex);
        }

        //create the reader
        FeatureReader<SimpleFeatureType, SimpleFeature> reader;

        String sql = null;
        try {
            // this allows PostGIS to page the results and respect the fetch size
            // if (getState().getTransaction() == Transaction.AUTO_COMMIT)
            cx.setAutoCommit(false);

            final SQLDialect dialect = getDialect();
            if (dialect instanceof PreparedStatementSQLDialect) {
                final PreparedStatement ps = queryBuilder.selectSQLPS(querySchema, preQuery, cx);
                reader = new JDBCFeatureReader(ps, cx, this, query.getTypeName(), querySchema, pkey, query.getHints());
            } else {
                //build up a statement for the content
                sql = queryBuilder.selectSQL(querySchema, preQuery);
                //getLogger().fine(sql);

                reader = new JDBCFeatureReader( sql, cx, this, query.getTypeName(), querySchema, pkey, query.getHints() );
            }
        } catch (SQLException e) {
            // close the connection
            closeSafe(cx);
            // safely rethrow
            throw new DataStoreException(e.getMessage()+" > "+ sql, e);
        } catch (IOException e) {
            // close the connection
            closeSafe(cx);
            // safely rethrow
            throw new DataStoreException(e);
        }


        // if post filter, wrap it
        if (postFilter != null && postFilter != Filter.INCLUDE) {
            reader = GenericFilterFeatureIterator.wrap(reader, postFilter);
            if(!returnedSchema.equals(querySchema))
                reader = GenericRetypeFeatureIterator.wrap(reader, returnedSchema,query.getHints());
        }

        //if we need to resample
//        final double[] resampling = query.getResolution();
//        if(resampling != null){
//            reader = GenericTransformFeatureIterator.wrap(reader, 
//                    new GeometryScaleTransformer(resampling[0], resampling[1]),query.getHints());
//        }        
        
        //if we need to reproject data
        final CoordinateReferenceSystem reproject = query.getCoordinateSystemReproject();
        if(reproject != null && !CRS.equalsIgnoreMetadata(reproject,type.getCoordinateReferenceSystem())){
            try {
                reader = GenericReprojectFeatureIterator.wrap(reader, reproject,query.getHints());
            } catch (FactoryException ex) {
                throw new DataStoreException(ex);
            } catch (SchemaException ex) {
                throw new DataStoreException(ex);
            }
        }

        //if we need to constraint type
        if(!returnedSchema.equals(querySchema)){
            reader = GenericRetypeFeatureIterator.wrap(reader, returnedSchema, query.getHints());
        }

        return reader;
    }

    private FeatureReader getSQLFeatureReader(final Query query) throws DataStoreException {

        final TextStatement stmt = (TextStatement) query.getSource();
        final String sql = stmt.getStatement();
        
        try {
            final SimpleFeatureType sft = (SimpleFeatureType) getFeatureType(query);
            final PrimaryKey pk = new NullPrimaryKey(sft.getTypeName());
            final Connection cx = getDataSource().getConnection();
            final JDBCFeatureReader reader = new JDBCFeatureReader(sql, cx, this, null, sft, pk, null);
            return reader;
        } catch (SchemaException ex) {
            throw new DataStoreException(ex);
        } catch (SQLException ex) {
            throw new DataStoreException(ex);
        } catch (IOException ex) {
            throw new DataStoreException(ex);
        }
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public FeatureWriter getFeatureWriter(final Name typeName, final Filter filter, final Hints hints) throws DataStoreException {
        try {
            return getFeatureWriterInternal(typeName, filter, EditMode.UPDATE_AND_INSERT, hints);
        } catch (IOException ex) {
            throw new DataStoreException(ex);
        }
    }

    @Override
    public FeatureWriter getFeatureWriterAppend(final Name typeName, final Hints hints) throws DataStoreException {
        try {
            return getFeatureWriterInternal(typeName, Filter.EXCLUDE, EditMode.INSERT, hints);
        } catch (IOException ex) {
            throw new DataStoreException(ex);
        }
    }

    private FeatureWriter getFeatureWriterInternal(final Name typeName, final Filter filter, 
            final EditMode mode, final Hints hints) throws DataStoreException, IOException {

        if(!isWritable(typeName)){
            throw new DataStoreException("Type "+ typeName + " is not writeable.");
        }

        final SimpleFeatureType type = (SimpleFeatureType) getFeatureType(typeName);

        //split the filter
        final Filter[] split = splitFilter(filter,type);


        Connection cx = null;
        FeatureWriter<SimpleFeatureType, SimpleFeature> writer;
        try {
            final PrimaryKey pkey = dbmodel.getPrimaryKey(typeName);
            cx = getDataSource().getConnection();

            //check for insert only
            if ( EditMode.INSERT == mode ) {
                //build up a statement for the content, inserting only so we dont want
                //the query to return any data ==> Filter.EXCLUDE
                final Query queryNone = QueryBuilder.filtered(typeName, Filter.EXCLUDE);
                if ( getDialect() instanceof PreparedStatementSQLDialect ) {
                    final PreparedStatement ps = queryBuilder.selectSQLPS(type, queryNone, cx);
                    return new JDBCInsertFeatureWriter( ps, cx, this, typeName, type, pkey, hints);
                }else{
                    final String sql = queryBuilder.selectSQL(type, queryNone);
                    getLogger().fine(sql);
                    return new JDBCInsertFeatureWriter( sql, cx, this, typeName, type, pkey, hints);
                }
            }


            // build up a statement for the content
            final Query preQuery = QueryBuilder.filtered(typeName, split[0]);

            if(getDialect() instanceof PreparedStatementSQLDialect) {
                final PreparedStatement ps = queryBuilder.selectSQLPS(type, preQuery, cx);
                if ( EditMode.UPDATE == mode ) {
                    writer = new JDBCUpdateFeatureWriter(ps, cx, this, typeName, type, pkey, hints);
                } else {
                    //update insert case
                    writer = new JDBCUpdateInsertFeatureWriter(ps, cx, this, typeName, type, pkey, null, hints);
                }
            } else {
                final String sql = queryBuilder.selectSQL(type, preQuery);
                getLogger().fine(sql);

                if ( EditMode.UPDATE == mode ) {
                    writer = new JDBCUpdateFeatureWriter( sql, cx, this, typeName, type, pkey, hints);
                } else {
                    //update insert case
                    writer = new JDBCUpdateInsertFeatureWriter( sql, cx, this, typeName, type, pkey, hints);
                }
            }

        } catch (SQLException e) {
            // close the connection
            closeSafe(cx);
            // now we can safely rethrow the exception
            throw new DataStoreException(e);
        }

        //check for post filter and wrap accordingly
        if ( split[1] != null && split[1] != Filter.INCLUDE ) {
            writer = GenericFilterFeatureIterator.wrap(writer, split[1]);
        }
        return writer;
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public long getCount(final Query query) throws DataStoreException {
        if(CUSTOM_SQL.equalsIgnoreCase(query.getLanguage())){
            final FeatureReader reader = getSQLFeatureReader(query);
            try{
                return DataUtilities.calculateCount(reader);
            }finally{
                reader.close();
            }
        }

        typeCheck(query.getTypeName());
        final FeatureType type = getFeatureType(query.getTypeName());

        //split the filter
        final Filter[] split = splitFilter( query.getFilter(),type );
        final Filter preFilter = split[0];
        final Filter postFilter = split[1];


        if ((postFilter != null) && (postFilter != Filter.INCLUDE)) {
            try {
                //calculate manually, dont use datastore optimization
                getLogger().fine("Calculating size manually");
                return DataUtilities.calculateCount(getFeatureReader(query));
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        } else {
            //no post filter, we have a preFilter, or preFilter is null..
            // either way we can use the datastore optimization
            final Connection cx;
            try {
                cx = getDataSource().getConnection();
            } catch (SQLException ex) {
                throw new DataStoreException(ex);
            }
            try {
                final QueryBuilder builder = new QueryBuilder(query);
                builder.setFilter(preFilter);
                final Query q = builder.buildQuery();
                int count = getCount(type, q, cx);
                // if native support for limit and offset is not implemented, we have to ajust the result
                if (!getDialect().isLimitOffsetSupported()) {
                    if (query.getStartIndex() > 0) {
                        if (query.getStartIndex() > count) {
                            count = 0;
                        } else {
                            count -= query.getStartIndex();
                        }
                    }
                    if (query.getMaxFeatures() > 0 && count > query.getMaxFeatures()) {
                        count = query.getMaxFeatures();
                    }
                }
                return count;
            } finally {
                closeSafe(cx);
            }
        }
    }

    /**
     * Returns the count of the features for a particular feature type / table.
     * Rely on the database count capabilities.
     */
    private int getCount(final FeatureType featureType, final Query query, final Connection cx)
            throws DataStoreException {

        final Statement st;
        final ResultSet rs;
        try {
            if (dialect instanceof PreparedStatementSQLDialect) {
                st = queryBuilder.selectCountSQLPS(featureType, query, cx);
                rs = ((PreparedStatement) st).executeQuery();
            } else {
                final String sql = queryBuilder.selectCountSQL(featureType, query);
                getLogger().log(Level.FINE, "Counting features: {0}", sql);

                st = cx.createStatement();
                rs = st.executeQuery(sql);
            }

            try {
                rs.next();
                return rs.getInt(1);
            } finally {
                closeSafe(rs);
                closeSafe(st);
            }
        } catch (SQLException e) {
            throw new DataStoreException("Error occured calculating count", e);
        }
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public Envelope getEnvelope(final Query query) throws DataStoreException, DataStoreRuntimeException {
        typeCheck(query.getTypeName());
        final SimpleFeatureType type = (SimpleFeatureType) getFeatureType(query.getTypeName());

        //split the filter
        final Filter[] split = splitFilter(query.getFilter(),type);
        final Filter preFilter = split[0];
        final Filter postFilter = split[1];

        final boolean canLimitOffset = dialect.isLimitOffsetSupported();

        if ((postFilter != null) && (postFilter != Filter.INCLUDE)
                || (query.getMaxFeatures() != null && !canLimitOffset)
                || (query.getStartIndex() > 0 && !canLimitOffset) ){
            //calculate manually, don't use datastore optimization
            getLogger().fine("Calculating bounds manually");

            // grab a reader
            final QueryBuilder builder = new QueryBuilder(query);
            builder.setFilter(postFilter);
            return DataUtilities.calculateEnvelope(getFeatureReader(builder.buildQuery()));
        } else {
            //post filter was null... pre can be set or null... either way
            // use datastore optimization
            final QueryBuilder builder = new QueryBuilder(query);
            builder.setFilter(preFilter);
            return getEnvelope(type, builder.buildQuery());
        }
    }

    /**
     * Returns the bounds of the features for a particular feature type / table.
     * Rely on tha database to obtain envelope.
     *
     * @param featureType The feature type / table.
     * @param query Specifies rows to include in bounds calculation, as well as how many
     *              features and the offset if needed
     */
    private Envelope getEnvelope(final FeatureType featureType, final Query query)
            throws DataStoreException {

        // handle geometryless case by returning a null envelope
        if (featureType.getGeometryDescriptor() == null) {
            return null;
        }

        Connection cx = null;
        Statement st = null;
        ResultSet rs = null;
        try {
            cx = getDataSource().getConnection();
            if (dialect instanceof PreparedStatementSQLDialect) {
                st = queryBuilder.selectBoundsSQLPS(featureType, query, cx);
                rs = ((PreparedStatement) st).executeQuery();
            } else {
                final String sql = queryBuilder.selectBoundsSQL(featureType, query);
                getLogger().log(Level.FINE, "Retriving bounding box: {0}", sql);
                st = cx.createStatement();
                rs = st.executeQuery(sql);
            }

            JTSEnvelope2D bbox = null;

            while(rs.next()){
                try {
                    final com.vividsolutions.jts.geom.Envelope e =
                            dialect.decodeGeometryEnvelope(rs, 1, st.getConnection());

                    if(e !=  null){
                        if(bbox == null){
                            final CoordinateReferenceSystem flatCRS = CRS.getHorizontalCRS(
                                featureType.getCoordinateReferenceSystem());
                            bbox = new JTSEnvelope2D(e, flatCRS);
                        }else{
                            bbox.expandToInclude(e);
                        }
                    }

                } catch (IOException ex) {
                    throw new DataStoreException(ex);
                }
            }
            
            return bbox;
        } catch (SQLException e) {
            throw new DataStoreException("Error occured calculating bounds", e);
        } finally {
            closeSafe(cx, st, rs);
        }
    }

    /**
     * Inserts a collection of new features into the database for a particular
     * feature type / table.
     * This method does not return the featureID.
     */
    protected void insert(final Collection<? extends Feature> features, final SimpleFeatureType featureType,
            final Connection cx) throws DataStoreException {
        final PrimaryKey key = dbmodel.getPrimaryKey(featureType.getName());

        // we do this in a synchronized block because we need to do two queries,
        // first to figure out what the id will be, then the insert statement
        synchronized (this) {
            Statement st = null;
            try {
                st = cx.createStatement();
                
                final List<Object> nextKeyValues = getNextValues(key, cx);
                final String sql = queryBuilder.insertSQL(featureType, features, nextKeyValues, cx);
                st.executeUpdate(sql);
                
            } catch (SQLException e) {
                throw new DataStoreException("Error inserting features",e);
            } catch (IOException e) {
                throw new DataStoreException("Error inserting features",e);
            }finally {
                closeSafe(st);
            }
        }
        
        fireFeaturesAdded(featureType.getName(), null);
    }
    
    /**
     * Inserts a collection of new features into the database for a particular
     * feature type / table.
     */
    protected void insert(final Feature ffeature, final SimpleFeatureType featureType,
            final Connection cx) throws DataStoreException {
        final PrimaryKey key = dbmodel.getPrimaryKey(featureType.getName());

        // we do this in a synchronized block because we need to do two queries,
        // first to figure out what the id will be, then the insert statement
        synchronized (this) {
            Statement st = null;
            try {
                if (!(dialect instanceof PreparedStatementSQLDialect)) {
                    st = cx.createStatement();
                }

                //figure out what the next fid will be
                final List<Object> nextKeyValues = getNextValues(key, cx);
                final SimpleFeature feature = (SimpleFeature) ffeature;

                if (dialect instanceof PreparedStatementSQLDialect) {
                    final PreparedStatement ps = queryBuilder.insertSQLPS(featureType, feature, nextKeyValues, cx);
                    try {
                        ps.execute();
                    } finally {
                        closeSafe(ps);
                    }
                } else {
                    //this technic must be generalize to all primary keys, must revisite tests for this
                    final String sql = queryBuilder.insertSQL(featureType, feature, nextKeyValues, cx);
                    getLogger().log(Level.FINE, "Inserting new feature: {0}", sql);

                    if(nextKeyValues.isEmpty() || nextKeyValues.get(0) == null){
                        st.execute(sql,Statement.RETURN_GENERATED_KEYS);
                        ResultSet rs = st.getGeneratedKeys();
                        rs.next();
                        final int id = rs.getInt(1);
                        nextKeyValues.set(0, id);
                        rs.close();
                        feature.setAttribute(key.getColumns().get(0).getName(), id);
                    }else{
                        st.execute(sql);
                    }
                }

                //report the feature id as user data since we cant set the fid
                final String fid = featureType.getTypeName() + "." + PrimaryKey.encodeFID(nextKeyValues);
                feature.getUserData().put("fid", fid);

            //st.executeBatch();
            } catch (SQLException e) {
                throw new DataStoreException("Error inserting features",e);
            } catch (IOException e) {
                throw new DataStoreException("Error inserting features",e);
            }finally {
                closeSafe(st);
            }
        }
        fireFeaturesAdded(featureType.getName(), null);
    }

    /**
     * Updates an existing feature(s) in the database for a particular feature type / table.
     */
    protected void update(final SimpleFeatureType featureType, final Map<AttributeDescriptor,Object> changes,
            final Filter filter, final Connection cx) throws DataStoreException{
        if ((changes == null) || (changes.isEmpty())) {
            getLogger().warning("Update called with no attributes, doing nothing.");
            return;
        }

        if (dialect instanceof PreparedStatementSQLDialect) {
            PreparedStatement ps = null;
            try {
                ps = queryBuilder.updateSQLPS(featureType, changes, filter, cx);
                ps.execute();
            }catch (SQLException e) {
                throw new DataStoreException("Error occured updating features",e);
            }finally {
                closeSafe(ps);
            }
        } else {
            Statement st = null;
            try {
                final String sql = queryBuilder.updateSQL(featureType, changes, filter);
                getLogger().log(Level.FINE, "Updating feature: {0}", sql);
                st = cx.createStatement();
                st.execute(sql);
            } catch (SQLException e) {
                throw new DataStoreException("Error occured updating features",e);
            } catch (IOException e) {
                throw new DataStoreException("Error occured updating features",e);
            } finally {
                closeSafe(st);
            }
        }
        fireFeaturesUpdated(featureType.getName(), null);
    }

    /**
     * Deletes an existing feature(s) in the database for a particular feature type / table.
     */
    protected void delete(final SimpleFeatureType featureType, final Filter filter, final Connection cx)
            throws IOException {

        Statement st = null;
        try {
            if (dialect instanceof PreparedStatementSQLDialect) {
                st = queryBuilder.deleteSQLPS(featureType, filter, cx);
                ((PreparedStatement) st).execute();
            } else {
                final String sql = queryBuilder.deleteSQL(featureType, filter);
                getLogger().log(Level.FINE, "Removing feature(s): {0}", sql);
                st = cx.createStatement();
                st.execute(sql);
            }
        } catch (SQLException e) {
            throw new IOException("Error occured calculating bounds", e);
        } finally {
            closeSafe(st);
        }
        fireFeaturesDeleted(featureType.getName(), null);
    }


    ////////////////////////////////////////////////////////////////////////////
    // schema manipulation /////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * {@inheritDoc }
     */
    @Override
    public void createSchema(final Name typeName, final FeatureType featureType) throws DataStoreException {

        if(typeName == null){
            throw new DataStoreException("Type name can not be null.");
        }

        if(!(featureType instanceof SimpleFeatureType)){
            throw new DataStoreException("JDBC datastore can handle only simple feature types.");
        }

        if(!featureType.getName().equals(typeName)){
            throw new DataStoreException("JDBC datastore can only hold typename same as feature type name.");
        }

        if(getNames().contains(typeName)){
            throw new DataStoreException("Type name "+ typeName + " already exists.");
        }


        //execute the create table statement
        //TODO: create a primary key and a spatial index
        Connection cx = null;

        try {
            cx = getDataSource().getConnection();
            final String sql = queryBuilder.createTableSQL((SimpleFeatureType) featureType,cx);
            getLogger().log(Level.FINE, "Create schema: {0}", sql);

            final Statement st = cx.createStatement();

            try {
                st.execute(sql);
            } finally {
                closeSafe(st);
            }

            dialect.postCreateTable(databaseSchema, (SimpleFeatureType)featureType, cx);
        } catch (Exception e) {
            throw new DataStoreException("Error occurred creating table", e);
        } finally {
            closeSafe(cx);
        }

        // reset the type name cache, will be recreated when needed.
        dbmodel.clearCache();
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public void updateSchema(final Name typeName, final FeatureType newft) throws DataStoreException {
        final FeatureType oldft = getFeatureType(typeName);
        
        //we only handle adding or removing columns
        final List<PropertyDescriptor> toRemove = new ArrayList<PropertyDescriptor>();
        final List<PropertyDescriptor> toAdd = new ArrayList<PropertyDescriptor>();
        
        toRemove.addAll(oldft.getDescriptors());
        toRemove.removeAll(newft.getDescriptors());
        toAdd.addAll(newft.getDescriptors());
        toAdd.removeAll(oldft.getDescriptors());
        
        Connection cx = null;
        
        try{            
            cx = getDataSource().getConnection();
            
            for(PropertyDescriptor remove : toRemove){
                final String sql = queryBuilder.AlterTableDropColumnSQL(oldft, remove, cx);                
                final Statement st = cx.createStatement();
                try {
                    st.execute(sql);
                } finally {
                    closeSafe(st);
                }                
            }
            
            for(PropertyDescriptor add : toAdd){
                final String sql = queryBuilder.AlterTableAddColumnSQL(oldft, add, cx);                
                final Statement st = cx.createStatement();
                try {
                    st.execute(sql);
                } finally {
                    closeSafe(st);
                }                
            }
            
        } catch (final Exception e) {
            throw new DataStoreException("Error occurred updating table", e);
        } finally{
            closeSafe(cx);
        }
        
        // reset the type name cache, will be recreated when needed.
        dbmodel.clearCache();
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public void deleteSchema(final Name typeName) throws DataStoreException {
        final FeatureType featureType = getFeatureType(typeName);
        
        //execute the drop table statement
        Connection cx = null;

        try {
            cx = getDataSource().getConnection();
            final String sql = queryBuilder.dropSQL(featureType);
            getLogger().log(Level.FINE, "Drop schema: {0}", sql);

            final Statement st = cx.createStatement();

            try {
                st.execute(sql);
            } finally {
                closeSafe(st);
            }
            
            // reset the type name cache, will be recreated when needed.
            dbmodel.clearCache();

        } catch (Exception e) {
            throw new DataStoreException("Error occurred drop table", e);
        } finally {
            closeSafe(cx);
        }
    }


    ////////////////////////////////////////////////////////////////////////////
    // SQL utils ///////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * Helper method for splitting a filter.
     */
    private Filter[] splitFilter(final Filter original, final FeatureType schema) throws DataStoreException {
        final Filter[] split = new Filter[2];
        if ( original != null ) {
            //create a filter splitter
            final CapabilitiesFilterSplitter splitter = new CapabilitiesFilterSplitter(
                    getFilterCapabilities(), schema);
            original.accept(splitter, null);

            split[0] = splitter.getPreFilter();
            split[1] = splitter.getPostFilter();
        }

        final SimplifyingFilterVisitor visitor = new SimplifyingFilterVisitor();
        final PrimaryKey key = dbmodel.getPrimaryKey(schema.getName());
        visitor.setFIDValidator( new PrimaryKeyFIDValidator( this,key ) );
        split[0] = (Filter) split[0].accept(visitor, null);
        split[1] = (Filter) split[1].accept(visitor, null);

        return split;
    }

    /**
     * The filter capabilities which reports which spatial operations the
     * underlying database can handle natively.
     *
     * @return The filter capabilities, never <code>null</code>.
     */
    private DefaultFilterCapabilities getFilterCapabilities() {
        if (dialect instanceof PreparedStatementSQLDialect) {
            return ((PreparedStatementSQLDialect) dialect).createPreparedFilterToSQL().getCapabilities();
        } else {
            return dialect.createFilterToSQL().getCapabilities();
        }
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public FilterToSQL createFilterToSQL(final FeatureType featureType) {
        return queryBuilder.initializeFilterToSQL(dialect.createFilterToSQL(), featureType);
    }

    /**
     * Gets the next value of a primary key.
     */
    protected List<Object> getNextValues(final PrimaryKey pkey, final Connection cx)
            throws SQLException, IOException {
        final ArrayList<Object> next = new ArrayList<Object>();
        for (PrimaryKeyColumn col : pkey.getColumns()) {
            next.add(getNextValue(col, pkey, cx));
        }
        return next;
    }

    /**
     * Gets the next value for the column of a primary key.
     */
    protected Object getNextValue(final PrimaryKeyColumn col, final PrimaryKey pkey, final Connection cx)
            throws SQLException, IOException {
        Object next = null;

        if (col instanceof AutoGeneratedPrimaryKeyColumn) {
            next = dialect.getNextAutoGeneratedValue(databaseSchema, pkey.getTableName(), col.getName(), cx);
        } else if (col instanceof SequencedPrimaryKeyColumn) {
            final String sequenceName = ((SequencedPrimaryKeyColumn) col).getSequenceName();
            next = dialect.getNextSequenceValue(databaseSchema, sequenceName, cx);
        } else {
            //try to calculate
            final Class t = col.getType();

            //is the column numeric?
            if (Number.class.isAssignableFrom(t)) {

                //search the max value.
                final StringBuilder sql = new StringBuilder();
                sql.append("SELECT MAX(");
                dialect.encodeColumnName(col.getName(), sql);
                sql.append(") FROM ");
                queryBuilder.encodeTableName(pkey.getTableName(), sql);
                getLogger().log(Level.FINE, "Getting next FID: {0}", sql);

                final Statement st = cx.createStatement();
                ResultSet rs = null;
                try {
                    rs = st.executeQuery(sql.toString());
                    rs.next();
                    next = rs.getObject(1);
                } finally {
                    closeSafe(rs);
                    closeSafe(st);
                }

                if(next == null){
                    //this probably means there was no data in the table, set to 1
                    //TODO: probably better to do a count to check... but if this
                    // value already exists the db will throw an error when it tries
                    // to insert
                    next = 1;
                }else if (t == Short.class || t == Integer.class || t == Long.class
                        || BigInteger.class.isAssignableFrom(t)
                        || BigDecimal.class.isAssignableFrom(t) ) {
                    next = ((Number)next).longValue() +1;
                }else if (t == Float.class){
                    next = Math.nextUp( ((Number)next).floatValue() );
                }else if (t == Double.class){
                    next = Math.nextUp( ((Number)next).doubleValue() );
                }else{
                    //can't calculate for other types
                    next = 1;
                }

            } else if (CharSequence.class.isAssignableFrom(t)) {
                //generate a random string
                next = SimpleFeatureBuilder.createDefaultFeatureId();
            }

            if (next == null) {
                throw new IOException("Cannot generate key value for column of type: " + t.getName());
            }
        }

        return next;
    }


    ////////////////////////////////////////////////////////////////////////////
    // Fallback on reader/write iterator methods ///////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * {@inheritDoc }
     */
    @Override
    public List<FeatureId> addFeatures(final Name groupName, final Collection<? extends Feature> newFeatures, 
            final Hints hints) throws DataStoreException {
        return handleAddWithFeatureWriter(groupName, newFeatures, hints);
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public void updateFeatures(final Name groupName, final Filter filter, final Map<? extends PropertyDescriptor, ? extends Object> values) throws DataStoreException {
        handleUpdateWithFeatureWriter(groupName, filter, values);
    }

    /**
     * {@inheritDoc }
     */
    @Override
    public void removeFeatures(final Name groupName, final Filter filter) throws DataStoreException {
        handleRemoveWithFeatureWriter(groupName, filter);
    }


    ////////////////////////////////////////////////////////////////////////////
    // other utils /////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    @Override
    protected void finalize() throws Throwable {
        if (source != null) {
            getLogger().severe("There's code using JDBC based datastore and " +
                    "not disposing them. This may lead to temporary loss of database connections. " +
                    "Please make sure all data access code calls DataStore.dispose() " +
                    "before freeing all references to it");
            dispose();
        }
        super.finalize();
    }

    @Override
    public void dispose() {
        if (source instanceof ManageableDataSource) {
            try {
                final ManageableDataSource mds = (ManageableDataSource) source;
                source = null;
                mds.close();
            } catch (SQLException e) {
                // it's ok, we did our best..
                getLogger().log(Level.FINE, "Could not close dataSource", e);
            }
        }
    }

}
