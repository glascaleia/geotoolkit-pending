/*
 *    Geotoolkit - An Open Source Java GIS Toolkit
 *    http://www.geotoolkit.org
 *
 *    (C) 2010, Geomatys
 *
 *    This library is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU Lesser General Public
 *    License as published by the Free Software Foundation;
 *    version 2.1 of the License.
 *
 *    This library is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *    Lesser General Public License for more details.
 */

package org.geotoolkit.jdbc.dialect;

import org.opengis.feature.Feature;
import java.util.Collection;
import com.vividsolutions.jts.geom.Geometry;

import java.io.IOException;
import java.sql.Connection;
import java.sql.DatabaseMetaData;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.sql.Types;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.logging.Level;

import org.geotoolkit.data.jdbc.FilterToSQL;
import org.geotoolkit.data.jdbc.FilterToSQLException;
import org.geotoolkit.data.jdbc.PreparedFilterToSQL;
import org.geotoolkit.data.jdbc.fidmapper.FIDMapper;
import org.geotoolkit.data.query.Query;
import org.geotoolkit.factory.Hints;
import org.geotoolkit.feature.FeatureTypeUtilities;
import org.geotoolkit.jdbc.AbstractJDBCDataStore;
import org.geotoolkit.jdbc.JDBCDataStore;
import org.geotoolkit.jdbc.fid.AutoGeneratedPrimaryKeyColumn;
import org.geotoolkit.jdbc.fid.NullPrimaryKey;
import org.geotoolkit.jdbc.fid.PrimaryKey;
import org.geotoolkit.jdbc.fid.PrimaryKeyColumn;
import org.geotoolkit.referencing.IdentifiedObjects;
import org.geotoolkit.storage.DataStoreException;

import org.opengis.feature.simple.SimpleFeature;
import org.opengis.feature.simple.SimpleFeatureType;
import org.opengis.feature.type.AttributeDescriptor;
import org.opengis.feature.type.FeatureType;
import org.opengis.feature.type.GeometryDescriptor;
import org.opengis.feature.type.PropertyDescriptor;
import org.opengis.filter.Filter;
import org.opengis.filter.PropertyIsLessThanOrEqualTo;
import org.opengis.filter.expression.Function;
import org.opengis.filter.expression.Literal;
import org.opengis.filter.expression.PropertyName;
import org.opengis.filter.sort.SortBy;
import org.opengis.filter.sort.SortOrder;
import org.opengis.referencing.crs.CoordinateReferenceSystem;

import static org.geotoolkit.util.ArgumentChecks.*;

/**
 * Create sql queries for JDBC Datastore, the queries syntax is
 * adjusted using the given SQLDialect.
 *
 * @author Johann Sorel (Geomatys)
 */
public final class SQLQueryBuilder {

    private final AbstractJDBCDataStore store;

    public SQLQueryBuilder(final AbstractJDBCDataStore store){
        ensureNonNull("JDBC DataStore", store);
        this.store = store;
    }

    private SQLDialect getDialect(){
        return store.getDialect();
    }


    ////////////////////////////////////////////////////////////////////////////
    // STATEMENT QURIES ////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * Generates a 'SELECT p1, p2, ... FROM ... WHERE ...' statement.
     *
     * @param featureType
     *            the feature type that the query must return (may contain less
     *            attributes than the native one)
     * @param query
     *            the query to be run. The type name and property will be ignored, as they are
     *            supposed to have been already embedded into the provided feature type
     * @return String
     */
    public String selectSQL(final FeatureType featureType, final Query query) throws SQLException,DataStoreException {
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder("SELECT ");

        final PrimaryKey key = store.getMetaModel().getPrimaryKey(featureType.getName());

        //column names
        for (PropertyDescriptor att : featureType.getDescriptors()) {
            if (att instanceof GeometryDescriptor) {
                //encode as geometry
                encodeGeometryColumn((GeometryDescriptor) att, sql, query.getHints());

                //alias it to be the name of the original geometry
                dialect.encodeColumnAlias(att.getName().getLocalPart(), sql);
            } else {
                dialect.encodeColumnName(att.getName().getLocalPart(), sql);
            }

            sql.append(',');
        }

        sql.setLength(sql.length() - 1);

        sql.append(" FROM ");
        encodeTableName(featureType.getName().getLocalPart(), sql);

        //filtering
        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                // grab the full feature type, as we might be encoding a filter
                // that uses attributes that aren't returned in the results
                final FeatureType fullSchema = store.getFeatureType(featureType.getName().getLocalPart());
                final FilterToSQL toSQL = store.createFilterToSQL(fullSchema);
                sql.append(' ').append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        //sorting
        sort(featureType, query.getSortBy(), key, sql);

        // finally encode limit/offset, if necessary
        applyLimitOffset(sql, query);

        return sql.toString();
    }

    /**
     * Generates a 'SELECT count(*) FROM' sql statement. In case limit/offset is
     * used, we'll need to apply them on a <code>select *<code>
     * as limit/offset usually alters the number of returned rows
     * (and a count returns just one), and then count on the result of that first select
     */
    public String selectCountSQL(final FeatureType featureType, final Query query) throws SQLException {
        final StringBuilder sql = new StringBuilder();

        final boolean limitOffset = checkLimitOffset(query);
        if (limitOffset) {
            sql.append("SELECT * FROM ");
        } else {
            sql.append("SELECT count(*) FROM ");
        }
        encodeTableName(featureType.getName().getLocalPart(), sql);

        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                final FilterToSQL toSQL = store.createFilterToSQL(featureType);
                sql.append(' ').append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        if (limitOffset) {
            applyLimitOffset(sql, query);
            sql.insert(0, "SELECT COUNT(*) FROM (");
            sql.append(") AS GT_COUNT_ ");

        }

        return sql.toString();
    }

    /**
     * Generates a 'SELECT' sql statement which selects bounds.
     *
     * @param featureType The feature type / table.
     * @param query Specifies which features are to be used for the bounds computation
     *              (and in particular uses filter, start index and max features)
     */
    public String selectBoundsSQL(final FeatureType featureType, final Query query) throws SQLException {
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder();

        final boolean offsetLimit = checkLimitOffset(query);
        if (offsetLimit) {
            // envelopes are aggregates, just like count, so we must first isolate
            // the rows against which the aggregate will work in a subquery
            sql.append(" SELECT *");
        } else {
            sql.append("SELECT ");
            buildEnvelopeAggregates(featureType, sql);
        }

        sql.append(" FROM ");
        encodeTableName(featureType.getName().getLocalPart(), sql);

        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                final FilterToSQL toSQL = store.createFilterToSQL(featureType);
                sql.append(" ").append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        // finally encode limit/offset, if necessary
        if (offsetLimit) {
            applyLimitOffset(sql, query);
            // build the prologue
            StringBuilder sb = new StringBuilder();
            sb.append("SELECT ");
            buildEnvelopeAggregates(featureType, sb);
            sb.append("FROM (");
            // wrap the existing query
            sql.insert(0, sb.toString());
            sql.append(')');
            dialect.encodeTableAlias("GT2_BOUNDS_", sql);
        }

        return sql.toString();
    }

    /**
     * Generates a 'INSERT INFO' sql statement.
     * @throws IOException
     */
    public String insertSQL(final SimpleFeatureType featureType, final SimpleFeature feature,
                               final List keyValues, final Connection cx) throws DataStoreException{
        final SQLDialect dialect = getDialect();
        final PrimaryKey key = store.getMetaModel().getPrimaryKey(featureType.getName());
        final List<PrimaryKeyColumn> keyColumns = key.getColumns();

        final StringBuilder sqlType = new StringBuilder();
        sqlType.append("INSERT INTO ");
        encodeTableName(featureType.getTypeName(), sqlType);
        sqlType.append(" ( ");

        final StringBuilder sqlValues = new StringBuilder();
        sqlValues.append(" ) VALUES ( ");

        //add all fields
        fields :
        for(int i=0,n=featureType.getAttributeCount(); i<n; i++){
            final AttributeDescriptor desc = featureType.getDescriptor(i);
            final String attName = desc.getLocalName();
            final Class binding = desc.getType().getBinding();
            final Object value = feature.getAttribute(attName);

            //remove the primary key attribut that wil be auto-generated and null
            for (PrimaryKeyColumn col : keyColumns) {
                if(col.getName().equals(attName)){
                    //only include if its non auto generating and not null
                    if (col instanceof AutoGeneratedPrimaryKeyColumn) {
                        if(value == null ||
                           (value instanceof Number && ((Number)value).intValue() <=0) ||
                           (value instanceof String && ((String)value).isEmpty()) ){
                        continue fields;
                        }
                    }
                }
            }

            //the column
            dialect.encodeColumnName(attName, sqlType);

            //the value
            if (value == null) {
                //maybe it's an auto generated value from a sequence
                boolean found = false;
                for (int k=0; k<keyColumns.size(); k++) {
                    if(keyColumns.get(k).getName().equals(attName)){
                        dialect.encodeValue(keyValues.get(k), keyColumns.get(k).getType(), sqlValues);
                        found = true;
                        break;
                    }
                }

                if(!found){
                    if (!desc.isNillable()) {
                        //TODO: throw an exception
                    }
                    sqlValues.append("null");
                }
            } else {
                if (Geometry.class.isAssignableFrom(binding)) {
                    final Geometry g = (Geometry) value;
                    final int srid = getGeometrySRID(g, desc);
                    try {
                        dialect.encodeGeometryValue(g, srid, sqlValues);
                    } catch (IOException ex) {
                        throw new DataStoreException(ex);
                    }
                } else {
                    dialect.encodeValue(value, binding, sqlValues);
                }
            }

            sqlType.append(',');
            sqlValues.append(',');
        }

        sqlType.setLength(sqlType.length() - 1);
        sqlValues.setLength(sqlValues.length() - 1);
        sqlValues.append(")");

        return sqlType.toString() + sqlValues.toString();
    }
    
    public String insertSQL(final SimpleFeatureType featureType, final Collection<? extends Feature> features,
                               final List keyValues, final Connection cx) throws DataStoreException{
        final SQLDialect dialect = getDialect();
        final PrimaryKey key = store.getMetaModel().getPrimaryKey(featureType.getName());
        final List<PrimaryKeyColumn> keyColumns = key.getColumns();

        final StringBuilder sqlType = new StringBuilder();
        sqlType.append("INSERT INTO ");
        encodeTableName(featureType.getTypeName(), sqlType);
        sqlType.append(" ( ");

        //add all fields
        fields :
        for(int i=0,n=featureType.getAttributeCount(); i<n; i++){
            final AttributeDescriptor desc = featureType.getDescriptor(i);
            final String attName = desc.getLocalName();

            //remove the primary key attribut that wil be auto-generated and null
            for (PrimaryKeyColumn col : keyColumns) {
                if(col.getName().equals(attName)){
                    //only include if its non auto generating and not null
                    if (col instanceof AutoGeneratedPrimaryKeyColumn) {
                        continue fields;
                    }
                }
            }

            //the column
            dialect.encodeColumnName(attName, sqlType);
            sqlType.append(',');
        }
        
        sqlType.setLength(sqlType.length() - 1);
        sqlType.append(" ) ");
        
        
        final StringBuilder sqlValues = new StringBuilder();
        sqlValues.append(" VALUES ");

        //add all fields
        for(Feature feature : features){
            
            sqlValues.append(" (");
            fields :
            for(int i=0,n=featureType.getAttributeCount(); i<n; i++){
                final AttributeDescriptor desc = featureType.getDescriptor(i);
                final String attName = desc.getLocalName();
                final Class binding = desc.getType().getBinding();
                final Object value = feature.getProperty(attName).getValue();

                //remove the primary key attribut that wil be auto-generated and null
                for (PrimaryKeyColumn col : keyColumns) {
                    if(col.getName().equals(attName)){
                        //only include if its non auto generating and not null
                        if (col instanceof AutoGeneratedPrimaryKeyColumn) {
                            continue fields;
                        }
                    }
                }

                //the value
                if (value == null) {
                    //maybe it's an auto generated value from a sequence
                    boolean found = false;
                    for (int k=0; k<keyColumns.size(); k++) {
                        if(keyColumns.get(k).getName().equals(attName)){
                            dialect.encodeValue(keyValues.get(k), keyColumns.get(k).getType(), sqlValues);
                            found = true;
                            break;
                        }
                    }

                    if(!found){
                        if (!desc.isNillable()) {
                            //TODO: throw an exception
                        }
                        sqlValues.append("null");
                    }
                } else {
                    if (Geometry.class.isAssignableFrom(binding)) {
                        final Geometry g = (Geometry) value;
                        final int srid = getGeometrySRID(g, desc);
                        try {
                            dialect.encodeGeometryValue(g, srid, sqlValues);
                        } catch (IOException ex) {
                            throw new DataStoreException(ex);
                        }
                    } else {
                        dialect.encodeValue(value, binding, sqlValues);
                    }
                }

                sqlValues.append(',');
            }
            sqlValues.setLength(sqlValues.length() - 1);
            sqlValues.append(" ),");
        }

        sqlValues.setLength(sqlValues.length() - 1);
        sqlValues.append(';');        
        
        return sqlType.toString() + sqlValues.toString();
    }
    

    /**
     * Generates an 'UPDATE' sql statement.
     */
    public String updateSQL(final SimpleFeatureType featureType, final Map<AttributeDescriptor,Object> changes,
            final Filter filter) throws IOException, SQLException{
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder();
        sql.append("UPDATE ");
        encodeTableName(featureType.getTypeName(), sql);

        sql.append(" SET ");

        for(final Entry<AttributeDescriptor,Object> change : changes.entrySet()){
            final AttributeDescriptor attribut = change.getKey();
            final Object value = change.getValue();

            dialect.encodeColumnName(attribut.getLocalName(), sql);
            sql.append('=');

            final Class binding = attribut.getType().getBinding();
            if (Geometry.class.isAssignableFrom(binding)) {
                    final Geometry g = (Geometry) value;
                    final int srid = getGeometrySRID(g, attribut);
                    dialect.encodeGeometryValue(g, srid, sql);
            } else {
                dialect.encodeValue(value, binding, sql);
            }

            sql.append(',');
        }

        sql.setLength(sql.length() - 1);
        sql.append(' ');

        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                final FilterToSQL toSQL = store.createFilterToSQL(featureType);
                sql.append(' ').append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        return sql.toString();
    }

    /**
     * Generates a 'DELETE FROM' sql statement.
     */
    public String deleteSQL(final SimpleFeatureType featureType, final Filter filter) throws SQLException {
        final StringBuilder sql = new StringBuilder("DELETE FROM ");
        encodeTableName(featureType.getTypeName(), sql);

        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                final FilterToSQL toSQL = store.createFilterToSQL(featureType);
                sql.append(" ").append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        return sql.toString();
    }

    /**
     * Generates a 'CREATE TABLE' sql statement.
     */
    public String createTableSQL(final SimpleFeatureType featureType, final Connection cx) throws SQLException {
        final SQLDialect dialect = getDialect();
        //figure out the names and types of the columns
        final String tableName = featureType.getTypeName();
        final int size = featureType.getAttributeCount();
        final String[] columnNames = new String[size];
        final Class[] classes = new Class[size];
        final boolean[] nillable = new boolean[size];
        final List<String> pkeyColumn = new ArrayList<String>();

        for (int i=0; i<size; i++) {
            final AttributeDescriptor desc = featureType.getDescriptor(i);
            columnNames[i] = desc.getLocalName();
            classes[i] = desc.getType().getBinding();
            nillable[i] = desc.getMinOccurs() <= 0 || desc.isNillable();

            if(FeatureTypeUtilities.isPartOfPrimaryKey(desc)){
                pkeyColumn.add(desc.getLocalName());
            }
        }

        final String[] sqlTypeNames = getSQLTypeNames(classes, cx);

        for (int i=0; i<sqlTypeNames.length; i++) {
            if (sqlTypeNames[i] == null) {
                throw new SQLException("Unable to map " + columnNames[i] + "( " + classes[i].getName() + ")");
            }
        }

        //build the create table sql -------------------------------------------
        final StringBuilder sql = new StringBuilder();
        sql.append("CREATE TABLE ");
        encodeTableName(tableName, sql);
        sql.append(" ( ");

        if(pkeyColumn.isEmpty()){
            //we create a primary key, this will modify the geature type but
            //we don't have any other solution
            dialect.encodeColumnName("fid", sql);
            dialect.encodePrimaryKey(Integer.class,"INTEGER", sql);
            sql.append(", ");
        }

        //normal attributes
        for (int i = 0; i < columnNames.length; i++) {
            final AttributeDescriptor att = featureType.getDescriptor(columnNames[i]);

            //the column name
            dialect.encodeColumnName(columnNames[i], sql);
            sql.append(' ');

            if(pkeyColumn.contains(columnNames[i])){
                dialect.encodePrimaryKey(att.getType().getBinding(), sqlTypeNames[i], sql);

            }else if (sqlTypeNames[i].toUpperCase().startsWith("VARCHAR")) {
                //sql type name
                //JD: some sql dialects require strings / varchars to have an
                // associated size with them
                Integer length = findVarcharColumnLength(att);
                if (length == null || length < 0) {
                    length = 255;
                }
                dialect.encodeColumnType(sqlTypeNames[i] + '(' + length + ')', sql);
            } else {
                dialect.encodeColumnType(sqlTypeNames[i], sql);
            }

            //nullable
            if (nillable != null && !nillable[i]) {
                sql.append(" NOT NULL ");
            }

            //delegate to dialect to encode column postamble
            dialect.encodePostColumnCreateTable(att, sql);

            //sql.append(sqlTypeNames[i]);
            if (i < (sqlTypeNames.length - 1)) {
                sql.append(", ");
            }
        }

        sql.append(" ) ");

        //encode anything post create table
        dialect.encodePostCreateTable(tableName, sql);

        return sql.toString();
    }

    /**
     * Generates a 'ALTER TABLE . ADD COLUMN ' sql statement.
     */
    public String AlterTableAddColumnSQL(final FeatureType featureType, final PropertyDescriptor desc, final Connection cx) throws SQLException{
        final SQLDialect dialect = getDialect();
        final String tableName = featureType.getName().getLocalPart();
        final boolean nillable = desc.getMinOccurs() <= 0 || desc.isNillable();
        final Class clazz = desc.getType().getBinding();
        final Integer sqlType = dialect.getMapping(clazz);
        final String sqlTypeName = getSQLTypeNames(new Class[]{clazz}, cx)[0];
        
        final StringBuilder sql = new StringBuilder();
        sql.append("ALTER TABLE ");
        encodeTableName(tableName, sql);
        sql.append(" ADD COLUMN ");
        dialect.encodeColumnName(desc.getName().getLocalPart(), sql);
        sql.append(' ');
        
        //encode type
        if (sqlTypeName.toUpperCase().startsWith("VARCHAR")) {
            //sql type name
            //JD: some sql dialects require strings / varchars to have an
            // associated size with them
            Integer length = findVarcharColumnLength((AttributeDescriptor)desc);
            if (length == null || length < 0) {
                length = 255;
            }
            dialect.encodeColumnType(sqlTypeName + '(' + length + ')', sql);
        } else {
            dialect.encodeColumnType(sqlTypeName, sql);
        }
        
        //nullable
        if (!nillable) {
            sql.append(" NOT NULL ");
        }

        return sql.toString();
    }
    
    /**
     * Generates a 'ALTER TABLE . DROP COLUMN ' sql statement.
     */
    public String AlterTableDropColumnSQL(final FeatureType featureType, final PropertyDescriptor desc, final Connection cx){
        final SQLDialect dialect = getDialect();
        final String tableName = featureType.getName().getLocalPart();        
        final StringBuilder sql = new StringBuilder();
        sql.append("ALTER TABLE ");
        encodeTableName(tableName, sql);
        sql.append(" DROP COLUMN ");
        dialect.encodeColumnName(desc.getName().getLocalPart(), sql);
        return sql.toString();
    }
    
    /**
     * Generates a 'DROP TABLE' sql statement.
     */
    public String dropSQL(final FeatureType featureType){
        final StringBuilder sql = new StringBuilder();
        sql.append("DROP TABLE ");
        encodeTableName(featureType.getName().getLocalPart(), sql);
        sql.append(";");
        return sql.toString();
    }
    
    ////////////////////////////////////////////////////////////////////////////
    // PREPARED STATEMENT QUERIES //////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * Generates a 'SELECT p1, p2, ... FROM ... WHERE ...' prepared statement.
     *
     * @param featureType
     *            the feature type that the query must return (may contain less
     *            attributes than the native one)
     * @param query
     *            the query to be run. The type name and property will be ignored, as they are
     *            supposed to have been already embedded into the provided feature type
     * @param cx
     *            The database connection to be used to create the prepared
     *            statement
     */
    public PreparedStatement selectSQLPS(final FeatureType featureType, final Query query,
                                            final Connection cx) throws SQLException, DataStoreException{
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder("SELECT ");

        // primary key
        final PrimaryKey key = store.getMetaModel().getPrimaryKey(featureType.getName());

        //other columns
        for (PropertyDescriptor att : featureType.getDescriptors()) {
            if (att instanceof GeometryDescriptor) {
                //encode as geometry
                encodeGeometryColumn((GeometryDescriptor) att, sql, query.getHints());

                //alias it to be the name of the original geometry
                dialect.encodeColumnAlias(att.getName().getLocalPart(), sql);
            } else {
                dialect.encodeColumnName(att.getName().getLocalPart(), sql);
            }

            sql.append(',');
        }

        sql.setLength(sql.length() - 1);

        sql.append(" FROM ");
        encodeTableName(featureType.getName().getLocalPart(), sql);

        //filtering
        PreparedFilterToSQL toSQL = null;
        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                // grab the full feature type, as we might be encoding a filter
                // that uses attributes that aren't returned in the results
                final FeatureType fullSchema = store.getFeatureType(featureType.getName());
                toSQL = createPreparedFilterToSQL(fullSchema);
                sql.append(' ').append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        //sorting
        sort(featureType, query.getSortBy(), key, sql);

        // finally encode limit/offset, if necessary
        applyLimitOffset(sql, query);

        store.getLogger().fine(sql.toString());
        final PreparedStatement ps = cx.prepareStatement(sql.toString(), ResultSet.TYPE_FORWARD_ONLY,
                                                                         ResultSet.CONCUR_READ_ONLY);
        ps.setFetchSize(store.getFetchSize());

        if (toSQL != null) {
            setPreparedFilterValues(ps, toSQL, 0, cx);
        }

        return ps;
    }

    /**
     * Generates a 'SELECT count(*) FROM' prepared statement.
     */
    public PreparedStatement selectCountSQLPS(final FeatureType featureType, final Query query,
                                                 final Connection cx) throws SQLException{
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder();

        final boolean limitOffset = checkLimitOffset(query);
        if (limitOffset) {
            sql.append("SELECT * FROM ");
        } else {
            sql.append("SELECT count(*) FROM ");
        }
        encodeTableName(featureType.getName().getLocalPart(), sql);

        PreparedFilterToSQL toSQL = null;
        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                toSQL = createPreparedFilterToSQL(featureType);
                sql.append(" ").append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        if (limitOffset) {
            applyLimitOffset(sql, query);
            sql.insert(0, "SELECT COUNT(*) FROM (");
            sql.append(")");
            dialect.encodeTableAlias("GT_COUNT_", sql);
        }

        store.getLogger().fine(sql.toString());
        final PreparedStatement ps = cx.prepareStatement(sql.toString());

        if (toSQL != null) {
            setPreparedFilterValues(ps, toSQL, 0, cx);
        }

        return ps;
    }

    /**
     * Generates a 'SELECT' prepared statement which selects bounds.
     *
     * @param featureType The feature type / table.
     * @param query Specifies which features are to be used for the bounds computation
     *              (and in particular uses filter, start index and max features)
     * @param cx A database connection.
     */
    public PreparedStatement selectBoundsSQLPS(final FeatureType featureType, final Query query,
                                                  final Connection cx) throws SQLException{
        final SQLDialect dialect = getDialect();
        final StringBuilder sql = new StringBuilder();

        final boolean offsetLimit = checkLimitOffset(query);
        if (offsetLimit) {
            // envelopes are aggregates, just like count, so we must first isolate
            // the rows against which the aggregate will work in a subquery
            sql.append(" SELECT *");
        } else {
            sql.append("SELECT ");
            buildEnvelopeAggregates(featureType, sql);
        }

        sql.append(" FROM ");
        encodeTableName(featureType.getName().getLocalPart(), sql);

        // encode the filter
        PreparedFilterToSQL toSQL = null;
        final Filter filter = query.getFilter();
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                toSQL = createPreparedFilterToSQL(featureType);
                sql.append(" ").append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        // finally encode limit/offset, if necessary
        if (offsetLimit) {
            applyLimitOffset(sql, query);
            // build the prologue
            final StringBuilder sb = new StringBuilder();
            sb.append("SELECT ");
            buildEnvelopeAggregates(featureType, sb);
            sb.append("FROM (");
            // wrap the existing query
            sql.insert(0, sb.toString());
            sql.append(")");
            dialect.encodeTableAlias("GT2_BOUNDS_", sql);
        }


        store.getLogger().fine(sql.toString());
        final PreparedStatement ps = cx.prepareStatement(sql.toString());

        if (toSQL != null) {
            setPreparedFilterValues(ps, toSQL, 0, cx);
        }

        return ps;
    }

    /**
     * Generates a 'INSERT INFO' prepared statement.
     */
    public PreparedStatement insertSQLPS(final SimpleFeatureType featureType, final SimpleFeature feature,
            final List keyValues, final Connection cx) throws IOException, SQLException, DataStoreException{
        final PreparedStatementSQLDialect dialect = (PreparedStatementSQLDialect) getDialect();
        final PrimaryKey key = store.getMetaModel().getPrimaryKey(featureType.getName());
        final List<PrimaryKeyColumn> keyColumns = key.getColumns();

        final StringBuilder sqlType = new StringBuilder();
        sqlType.append("INSERT INTO ");
        encodeTableName(featureType.getName().getLocalPart(), sqlType);
        sqlType.append(" ( ");

        final StringBuilder sqlValues = new StringBuilder();
        sqlValues.append(" ) VALUES ( ");

        //add all fields
        fields :
        for(int i=0,n=featureType.getAttributeCount(); i<n; i++){
            final AttributeDescriptor desc = featureType.getDescriptor(i);
            final String attName = desc.getLocalName();
            final Class binding = desc.getType().getBinding();
            final Object value = feature.getAttribute(attName);

            //remove the primary key attribut that wil be auto-generated and null
            for (PrimaryKeyColumn col : keyColumns) {
                if(col.getName().equals(attName)){
                    //only include if its non auto generating and not null
                    if (col instanceof AutoGeneratedPrimaryKeyColumn && value == null) {
                        continue fields;
                    }
                }
            }

            //the column
            dialect.encodeColumnName(attName, sqlType);

            //the value
            if (value == null) {
                sqlValues.append("?");
            } else {
                if (Geometry.class.isAssignableFrom(binding)) {
                    final Geometry g = (Geometry) value;
                    final int srid = getGeometrySRID(g, desc);
                    dialect.prepareGeometryValue(g, srid, binding, sqlValues);
                } else {
                    sqlValues.append("?");
                }
            }

            sqlType.append(',');
            sqlValues.append(',');
        }

        sqlType.setLength(sqlType.length() - 1);
        sqlValues.setLength(sqlValues.length() - 1);
        sqlValues.append(")");
        final String request = sqlType.toString() + sqlValues.toString();


        //create the prepared statement-----------------------------------------
        final PreparedStatement ps = cx.prepareStatement(request);

        //fill the prepared statement
        int attIdx = 0;
        fields :
        for(int i=0,n=featureType.getAttributeCount(); i<n; i++){
            final AttributeDescriptor desc = featureType.getDescriptor(i);
            final String attName = desc.getLocalName();
            final Class binding = desc.getType().getBinding();
            final Object value = feature.getAttribute(attName);

            //remove the primary key attribut that wil be auto-generated and null
            for (PrimaryKeyColumn col : keyColumns) {
                if(col.getName().equals(attName)){
                    //only include if its non auto generating and not null
                    if (col instanceof AutoGeneratedPrimaryKeyColumn && value == null) {
                        continue fields;
                    }
                }
            }

            attIdx++;

            //the column
            dialect.encodeColumnName(attName, sqlType);

            //the value
            if (value == null) {
                //maybe it's an auto generated value from a sequence
                boolean found = false;
                for (int k=0; k<keyColumns.size(); k++) {
                    if(keyColumns.get(k).getName().equals(attName)){
                        dialect.setValue(keyValues.get(k), keyColumns.get(k).getType(), ps, attIdx, cx);
                        found = true;
                        break;
                    }
                }

                if(!found){
                    if (!desc.isNillable()) {
                        //TODO: throw an exception
                    }
                    dialect.setValue(value, binding, ps, attIdx, cx);
                }
            } else {
                if (Geometry.class.isAssignableFrom(binding)) {
                    final Geometry g = (Geometry) value;
                    final int srid = getGeometrySRID(g, desc);
                    dialect.setGeometryValue(g, srid, binding, ps, attIdx);
                } else {
                    dialect.setValue(value, binding, ps, attIdx, cx);
                }
            }

            sqlType.append(',');
            sqlValues.append(',');
        }

        return ps;
    }

    /**
     * Generates an 'UPDATE' prepared statement.
     */
    public PreparedStatement updateSQLPS(final SimpleFeatureType featureType,
            final Map<AttributeDescriptor,Object> changes, final Filter filter,
            final Connection cx) throws SQLException{
        final PreparedStatementSQLDialect dialect = (PreparedStatementSQLDialect) getDialect();

        final StringBuilder sql = new StringBuilder();
        sql.append("UPDATE ");
        encodeTableName(featureType.getTypeName(), sql);
        sql.append(" SET ");

        for (Entry<AttributeDescriptor,Object> change : changes.entrySet()) {
            final AttributeDescriptor att = change.getKey();
            final Object value = change.getValue();
            dialect.encodeColumnName(att.getLocalName(), sql);
            sql.append('=');

            // geometries might need special treatment, delegate to the dialect
            if (att instanceof GeometryDescriptor) {
                final Geometry geometry = (Geometry) value;
                final Class<?> binding = att.getType().getBinding();
                dialect.prepareGeometryValue(geometry, getDescriptorSRID(att), binding, sql);
            } else {
                sql.append("?");
            }
            sql.append(',');
        }
        sql.setLength(sql.length() - 1);
        sql.append(' ');

        PreparedFilterToSQL toSQL = null;
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                toSQL = createPreparedFilterToSQL(featureType);
                sql.append(' ').append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        final PreparedStatement ps = cx.prepareStatement(sql.toString());
        store.getLogger().log(Level.FINE, "Updating features with prepared statement: {0}", sql);

        //fill the prepared statement
        int i = 0;
        for (Entry<AttributeDescriptor,Object> change : changes.entrySet()) {
            final AttributeDescriptor att = change.getKey();
            final Object value = change.getValue();
            final Class binding = att.getType().getBinding();
            if (Geometry.class.isAssignableFrom(binding)) {
                final Geometry g = (Geometry) value;
                dialect.setGeometryValue(g, getDescriptorSRID(att), binding, ps, i + 1);
            } else {
                dialect.setValue(value, binding, ps, i + 1, cx);
            }
            if (store.getLogger().isLoggable(Level.FINE)) {
                store.getLogger().fine((i + 1) + " = " + value);
            }
            i++;
        }

        if (toSQL != null) {
            setPreparedFilterValues(ps, toSQL, i, cx);
        //for ( int j = 0; j < toSQL.getLiteralValues().size(); j++, i++)  {
        //    Object value = toSQL.getLiteralValues().get( j );
        //    Class binding = toSQL.getLiteralTypes().get( j );
        //
        //    dialect.setValue( value, binding, ps, i+1, cx );
        //    if ( getLogger().isLoggable( Level.FINE ) ) {
        //        getLogger().fine( (i+1) + " = " + value );
        //}
        }

        return ps;
    }

    /**
     * Generates a 'DELETE FROM' prepared statement.
     */
    public PreparedStatement deleteSQLPS(final SimpleFeatureType featureType, final Filter filter,
                                            final Connection cx) throws SQLException {
        final StringBuilder sql = new StringBuilder("DELETE FROM ");
        encodeTableName(featureType.getTypeName(), sql);

        PreparedFilterToSQL toSQL = null;
        if (filter != null && !Filter.INCLUDE.equals(filter)) {
            //encode filter
            try {
                toSQL = createPreparedFilterToSQL(featureType);
                sql.append(" ").append(toSQL.encodeToString(filter));
            } catch (FilterToSQLException e) {
                throw new SQLException(e);
            }
        }

        store.getLogger().fine(sql.toString());
        final PreparedStatement ps = cx.prepareStatement(sql.toString());

        if (toSQL != null) {
            setPreparedFilterValues(ps, toSQL, 0, cx);
        }

        return ps;
    }


    ////////////////////////////////////////////////////////////////////////////
    // OTHER UTILS /////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////


    /**
     * Helper method for determining what the sql type names are for a set of
     * classes.
     * <p>
     * This method uses a combination of dialect mappings and database metadata
     * to determine which sql types map to the specified classes.
     * </p>
     */
    private String[] getSQLTypeNames(final Class[] classes, final Connection cx)
            throws SQLException {
        final SQLDialect dialect = getDialect();
        //figure out what the sql types are corresponding to the feature type
        // attributes
        final int[] sqlTypes = new int[classes.length];
        final String[] sqlTypeNames = new String[sqlTypes.length];

        for (int i = 0; i < classes.length; i++) {
            final Class clazz = classes[i];
            Integer sqlType = dialect.getMapping(clazz);

            if (sqlType == null) {
                store.getLogger().warning("No sql type mapping for: " + clazz);
                sqlType = Types.OTHER;
            }

            sqlTypes[i] = sqlType;

            //if this a geometric type, get the name from teh dialect
            //if ( attributeType instanceof GeometryDescriptor ) {
            if (Geometry.class.isAssignableFrom(clazz)) {
                String sqlTypeName = dialect.getGeometryTypeName(sqlType);

                if (sqlTypeName != null) {
                    sqlTypeNames[i] = sqlTypeName;
                }
            }

            //check the overrides
            final String sqlTypeName = dialect.getSqlTypeToSqlTypeNameOverrides().get(sqlType);
            if (sqlTypeName != null) {
                sqlTypeNames[i] = sqlTypeName;
            }

        }

        //figure out the type names that correspond to the sql types from
        // the database metadata
        final DatabaseMetaData metaData = cx.getMetaData();

        /*
         *      <LI><B>TYPE_NAME</B> String => Type name
         *        <LI><B>DATA_TYPE</B> int => SQL data type from java.sql.Types
         *        <LI><B>PRECISION</B> int => maximum precision
         *        <LI><B>LITERAL_PREFIX</B> String => prefix used to quote a literal
         *      (may be <code>null</code>)
         *        <LI><B>LITERAL_SUFFIX</B> String => suffix used to quote a literal
        (may be <code>null</code>)
         *        <LI><B>CREATE_PARAMS</B> String => parameters used in creating
         *      the type (may be <code>null</code>)
         *        <LI><B>NULLABLE</B> short => can you use NULL for this type.
         *      <UL>
         *      <LI> typeNoNulls - does not allow NULL values
         *      <LI> typeNullable - allows NULL values
         *      <LI> typeNullableUnknown - nullability unknown
         *      </UL>
         *        <LI><B>CASE_SENSITIVE</B> boolean=> is it case sensitive.
         *        <LI><B>SEARCHABLE</B> short => can you use "WHERE" based on this type:
         *      <UL>
         *      <LI> typePredNone - No support
         *      <LI> typePredChar - Only supported with WHERE .. LIKE
         *      <LI> typePredBasic - Supported except for WHERE .. LIKE
         *      <LI> typeSearchable - Supported for all WHERE ..
         *      </UL>
         *        <LI><B>UNSIGNED_ATTRIBUTE</B> boolean => is it unsigned.
         *        <LI><B>FIXED_PREC_SCALE</B> boolean => can it be a money value.
         *        <LI><B>AUTO_INCREMENT</B> boolean => can it be used for an
         *      auto-increment value.
         *        <LI><B>LOCAL_TYPE_NAME</B> String => localized version of type name
         *      (may be <code>null</code>)
         *        <LI><B>MINIMUM_SCALE</B> short => minimum scale supported
         *        <LI><B>MAXIMUM_SCALE</B> short => maximum scale supported
         *        <LI><B>SQL_DATA_TYPE</B> int => unused
         *        <LI><B>SQL_DATETIME_SUB</B> int => unused
         *        <LI><B>NUM_PREC_RADIX</B> int => usually 2 or 10
         */
        final ResultSet types = metaData.getTypeInfo();

        try {
            while (types.next()) {
                final int sqlType = types.getInt("DATA_TYPE");
                final String sqlTypeName = types.getString("TYPE_NAME");

                for (int i = 0; i < sqlTypes.length; i++) {
                    //check if we already have the type name from the dialect
                    if (sqlTypeNames[i] != null) {
                        continue;
                    }

                    if (sqlType == sqlTypes[i]) {
                        sqlTypeNames[i] = sqlTypeName;
                    }
                }
            }
        } finally {
            store.closeSafe(types);
        }

        // apply the overrides specified by the dialect
        final Map<Integer, String> overrides = dialect.getSqlTypeToSqlTypeNameOverrides();
        for (int i = 0; i < sqlTypes.length; i++) {
            final String override = overrides.get(sqlTypes[i]);
            if (override != null) {
                sqlTypeNames[i] = override;
            }
        }

        return sqlTypeNames;
    }


    /**
     * Applies the limit/offset elements to the query if they are specified
     * and if the dialect supports them
     * @param sql The sql to be modified
     * @param the query that holds the limit and offset parameters
     */
    public void applyLimitOffset(final StringBuilder sql, final Query query) {
        final SQLDialect dialect = getDialect();
        if (checkLimitOffset(query)) {
            final int offset = query.getStartIndex();
            final Integer limit = query.getMaxFeatures();
            dialect.applyLimitOffset(sql, limit, offset);
        }
    }

    /**
     * Checks if the query needs limit/offset treatment
     * @param query
     * @return true if the query needs limit/offset treatment and if the sql dialect can do that natively
     */
    public boolean checkLimitOffset(final Query query) {
        final SQLDialect dialect = getDialect();
        // if we cannot, don't bother checking the query
        if (!dialect.isLimitOffsetSupported()) {
            return false;
        }

        // the check the query has at least a non default value for limit/offset
        final int offset = query.getStartIndex();
        final Integer limit = query.getMaxFeatures();
        return limit != null || offset > 0;
    }

     /**
     * Encodes the sort-by portion of an sql query
     * @param featureType
     * @param sort
     * @param key
     * @param sql
     * @throws IOException
     */
    public void sort(final FeatureType featureType, final SortBy[] sort, final PrimaryKey key,
            final StringBuilder sql) throws DataStoreException {
        final SQLDialect dialect = getDialect();
        if ((sort != null) && (sort.length > 0)) {
            sql.append(" ORDER BY ");

            for (final SortBy sortBy : sort) {
                final String order;
                if (sortBy.getSortOrder() == SortOrder.DESCENDING) {
                    order = " DESC";
                } else {
                    order = " ASC";
                }

                if (SortBy.NATURAL_ORDER.equals(sortBy) || SortBy.REVERSE_ORDER.equals(sortBy)) {
                    if (key instanceof NullPrimaryKey) {
                        throw new DataStoreException("Cannot do natural order without a primary key");
                    }

                    for (PrimaryKeyColumn col : key.getColumns()) {
                        dialect.encodeColumnName(col.getName(), sql);
                        sql.append(order);
                        sql.append(',');
                    }
                } else {
                    dialect.encodeColumnName(getPropertyName(featureType, sortBy.getPropertyName()), sql);
                    sql.append(order);
                    sql.append(',');
                }
            }

            sql.setLength(sql.length() - 1);
        }
    }

    /**
     * Helper method to encode table name which checks if a schema is set and
     * prefixes the table name with it.
     */
    public void encodeTableName(final String tableName, final StringBuilder sql) {
        final SQLDialect dialect = getDialect();
        final String databaseSchema = store.getDatabaseSchema();
        if (databaseSchema != null) {
            dialect.encodeSchemaName(databaseSchema, sql);
            sql.append('.');
        }

        dialect.encodeTableName(tableName, sql);
    }

    /**
     * Encoding a geometry column with respect to hints
     * Supported Hints are provided by {@link SQLDialect#addSupportedHints(Set)}
     *
     * @param gatt
     * @param sql
     * @param hints , may be null
     */
    public void encodeGeometryColumn(final GeometryDescriptor gatt, final StringBuilder sql,
                                        final Hints hints){
        final SQLDialect dialect = getDialect();
        final int srid = getDescriptorSRID(gatt);
        dialect.encodeGeometryColumn(gatt, srid, sql,hints);
    }

    /**
     * Looks up the geometry srs by trying a number of heuristics. Returns -1 if all attempts
     * at guessing the srid failed.
     */
    public static int getGeometrySRID(final Geometry g, final AttributeDescriptor descriptor) {
        int srid = getDescriptorSRID(descriptor);

        if (g == null) {
            return srid;
        }

        // check for srid in the jts geometry then
        if (srid <= 0 && g.getSRID() > 0) {
            srid = g.getSRID();
        }

        // check if the geometry has anything
        if (srid <= 0) {
            // check for crs object
            final CoordinateReferenceSystem crs = (CoordinateReferenceSystem) g.getUserData();

            if (crs != null) {
                try {
                    final Integer candidate = IdentifiedObjects.lookupEpsgCode(crs, false);
                    if (candidate != null) {
                        srid = candidate;
                    }
                } catch (Exception e) {
                    // ok, we tried...
                }
            }
        }

        return srid;
    }

    /**
     * Extracts the eventual native SRID user property from the descriptor,
     * returns -1 if not found
     * @param descriptor
     */
    public static int getDescriptorSRID(final AttributeDescriptor descriptor) {
        // check if we have stored the native srid in the descriptor (we should)
        if (descriptor.getUserData().get(JDBCDataStore.JDBC_NATIVE_SRID) != null) {
            return (Integer) descriptor.getUserData().get(JDBCDataStore.JDBC_NATIVE_SRID);
        }else{
            return -1;
        }
    }

    /**
     * Helper method for executing a property name against a feature type.
     * <p>
     * This method will fall back on {@link PropertyName#getPropertyName()} if
     * it does not evaulate against the feature type.
     * </p>
     */
    public static String getPropertyName(final FeatureType featureType, final PropertyName propertyName) {
        final PropertyDescriptor att = (PropertyDescriptor) propertyName.evaluate(featureType);

        if (att != null) {
            return att.getName().getLocalPart();
        }

        return propertyName.getPropertyName();
    }

    /**
     * Builds a list of the aggregate function calls necesary to compute each geometry
     * column bounds
     * @param featureType
     * @param sql
     */
    public void buildEnvelopeAggregates(final FeatureType featureType, final StringBuilder sql) {
        final SQLDialect dialect = getDialect();
        //walk through all geometry attributes and build the query
        for(PropertyDescriptor desc : featureType.getDescriptors()){
            if (desc instanceof GeometryDescriptor) {
                final String geometryColumn = featureType.getGeometryDescriptor().getLocalName();
                dialect.encodeGeometryEnvelope(featureType.getName().getLocalPart(), geometryColumn, sql);
                sql.append(',');
            }
        }
        sql.setLength(sql.length() - 1);
    }

    /**
     * Searches the attribute descriptor restrictions in an attempt to determine
     * the length of the specified varchar column.
     */
    private static Integer findVarcharColumnLength(final AttributeDescriptor att) {
        for (final Filter r : att.getType().getRestrictions()) {
            if (r instanceof PropertyIsLessThanOrEqualTo) {
                final PropertyIsLessThanOrEqualTo c = (PropertyIsLessThanOrEqualTo) r;
                if (c.getExpression1() instanceof Function &&
                        ((Function) c.getExpression1()).getName().toLowerCase().endsWith("length")) {
                    if (c.getExpression2() instanceof Literal) {
                        final Integer length = c.getExpression2().evaluate(null, Integer.class);
                        if (length != null) {
                            return length;
                        }
                    }
                }
            }
        }

        return null;
    }


    ////////////////////////////////////////////////////////////////////////////
    // FILTER STUFFS ///////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////////////////

    /**
     * Creates a new instance of a filter to sql encoder to be
     * used in a prepared statement.
     */
    public PreparedFilterToSQL createPreparedFilterToSQL(final FeatureType featureType) {
        final SQLDialect dialect = getDialect();
        return initializeFilterToSQL(((PreparedStatementSQLDialect) dialect).createPreparedFilterToSQL(), featureType);
    }

    /**
     * Helper method to initialize a filter encoder instance.
     */
    public <F extends FilterToSQL> F initializeFilterToSQL(final F toSQL, final FeatureType featureType) {
        final SQLDialect dialect = getDialect();
        toSQL.setSqlNameEscape(dialect.getNameEscape());

        if (featureType != null) {
            //set up a fid mapper
            //TODO: remove this
            final PrimaryKey key;

            try {
                key = store.getMetaModel().getPrimaryKey(featureType.getName());
            } catch (DataStoreException e) {
                throw new RuntimeException(e);
            }

            FIDMapper mapper = new FIDMapper() {

                @Override
                public String createID(Connection conn, SimpleFeature feature, Statement statement)
                        throws IOException {
                    return null;
                }

                @Override
                public int getColumnCount() {
                    return key.getColumns().size();
                }

                @Override
                public int getColumnDecimalDigits(int colIndex) {
                    return 0;
                }

                @Override
                public String getColumnName(int colIndex) {
                    return key.getColumns().get(colIndex).getName();
                }

                @Override
                public int getColumnSize(int colIndex) {
                    return 0;
                }

                @Override
                public int getColumnType(int colIndex) {
                    return 0;
                }

                @Override
                public String getID(Object[] attributes) {
                    return null;
                }

                @Override
                public Object[] getPKAttributes(String FID) throws IOException {
                    return PrimaryKey.decodeFID(key, FID, false).toArray();
                }

                @Override
                public boolean hasAutoIncrementColumns() {
                    return false;
                }

                @Override
                public void initSupportStructures() {
                }

                @Override
                public boolean isAutoIncrement(int colIndex) {
                    return false;
                }

                @Override
                public boolean isVolatile() {
                    return false;
                }

                @Override
                public boolean returnFIDColumnsAsAttributes() {
                    return false;
                }

                @Override
                public boolean isValid(String fid) {
                    return true;
                }
            };
            toSQL.setFeatureType((SimpleFeatureType)featureType);
            toSQL.setFIDMapper(mapper);
        }

        return toSQL;
    }

    /**
     * Helper method for setting the values of the WHERE class of a prepared statement.
     *
     */
    public void setPreparedFilterValues(final PreparedStatement ps, final PreparedFilterToSQL toSQL,
                                           final int offset, final Connection cx) throws SQLException{
        final PreparedStatementSQLDialect dialect = (PreparedStatementSQLDialect) getDialect();

        for (int i = 0; i < toSQL.getLiteralValues().size(); i++) {
            final Object value = toSQL.getLiteralValues().get(i);
            final Class binding = toSQL.getLiteralTypes().get(i);
            Integer srid = toSQL.getSRIDs().get(i);
            if (srid == null) {
                srid = -1;
            }

            if (binding != null && Geometry.class.isAssignableFrom(binding)) {
                dialect.setGeometryValue((Geometry) value, srid, binding, ps, offset + i + 1);
            } else {
                dialect.setValue(value, binding, ps, offset + i + 1, cx);
            }
            if (store.getLogger().isLoggable(Level.FINE)) {
                store.getLogger().fine((i + 1) + " = " + value);
            }
        }
    }


}
